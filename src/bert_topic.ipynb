{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.analysis_helpers import *\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# ! python -m spacy download en_core_web_sm\n",
    "from bertopic.representation import KeyBERTInspired, PartOfSpeech, MaximalMarginalRelevance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '../interviews_corrected/6_final/**/' \n",
    "\n",
    "df_all = load_and_combine_csv(directory)\n",
    "df_all = standardize_data(df_all)\n",
    "\n",
    "print(f\"Unique conditions before filtering: {df_all['Condition'].unique()}\")\n",
    "print(f\"Number of interviews before filtering: {df_all['File Name'].nunique()}\")\n",
    "# *0*: No \"real\" interview (e.g., setup phase, small talk). We filter these out.\n",
    "df_all = df_all[df_all[\"Condition\"] != 0]\n",
    "print(f\"Unique conditions after filtering: {df_all['Condition'].unique()}\")\n",
    "print(f\"Number of interviews (File Name) after filtering: {df_all['File Name'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preoprocessing\n",
    "# For the moment only focus on the participants answers\n",
    "df = df_all[df_all[\"Speaker\"] == \"Participant\"].copy()\n",
    "# select only one experiment\n",
    "df = df[df[\"Experiment\"] == \"OBE2\"]\n",
    "\n",
    "# Stop words were removed using the NLTK library of stop words. \n",
    "# All text was lowercased + lemmatized\n",
    "# Plus extra_stopwords being the most frequents words in the corpus AND being meaningless (e.g. keep \"body\")\n",
    "extra_stopwords = [\"yeah\",\"like\",\"think\",\"know\",\"dont\",\"yes\",\"okay\",\"mm\"\"really\",\"bit\",\"could\",\"that's\",\"exactly\",\n",
    "                   \"see\",\"feel\",\"felt\",\"ah\",\"oh\",\"also\",\"I've\",\"maybe\",\"was\",\"thinking\",\"thought\",\"really\",\"thing\",\"part\",\"would\",\"said\",\n",
    "                   \"one\",\"first\",\"second\",\"meditation\"]\n",
    "df['preprocessed_content'] = df['Content'].apply(lambda x: preprocess_text(x, extra_stopwords=extra_stopwords, ngrams=1))\n",
    "\n",
    "# Remove rows with empty content or content that's only punctuation after preprocessing\n",
    "df = df[df['preprocessed_content'].str.strip().str.len() > 0]\n",
    "# File S225 is removed because it is empty after preprocessing (only two utterances, not meaningful words for topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.groupby(['File Name',\"utterance_index\"]).agg({ #,\n",
    "#     'preprocessed_content': ' '.join,  # Combine preprocessed text\n",
    "#     'Content': ' '.join,  # Combine raw text\n",
    "#     'Experiment': 'first',   # Keep the first \n",
    "#     'Condition': 'first',   # Keep the first\n",
    "#     'Id': 'first',   # Keep the first\n",
    "# }).reset_index()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = list(df.preprocessed_content)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look rows with a specific word in the column preprocessed_content\n",
    "df[df['preprocessed_content'].str.contains(\" one \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.2*len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(20 * 100) / len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "# Pre-calculate embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = embedding_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "umap_model = UMAP(n_neighbors=20, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n",
    "\n",
    "hdbscan_model = KMeans(n_clusters=10)\n",
    "#hdbscan_model = HDBSCAN(min_cluster_size=10, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "main_representation_model = KeyBERTInspired()\n",
    "aspect_representation_model1 = PartOfSpeech(\"en_core_web_sm\")\n",
    "aspect_representation_model2 = [KeyBERTInspired(top_n_words=30), \n",
    "                                MaximalMarginalRelevance(diversity=.5)]\n",
    "\n",
    "representation_model = {\n",
    "   \"Main\": main_representation_model,\n",
    "   \"Aspect1\":  aspect_representation_model1,\n",
    "   \"Aspect2\":  aspect_representation_model2 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(                       \n",
    "# Pipeline models\n",
    "embedding_model=embedding_model,\n",
    "umap_model=umap_model,\n",
    "hdbscan_model=hdbscan_model,\n",
    "representation_model = representation_model,\n",
    "\n",
    "# Hyperparameters\n",
    "verbose=True,)\n",
    "#min_topic_size=5)\n",
    "#n_gram_range=(1,2),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, ini_probs = topic_model.fit_transform(docs)\n",
    "num_topics = len(topic_model.get_topics()) - 1\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().to_csv(\"topic_info.csv\", index=False)\n",
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info(-1).Count / len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics = 16, n_words = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['one_topic'] = topics\n",
    "topic_name_to_id = dict(zip(topic_model.get_topic_info().Topic, topic_model.get_topic_info().Name))\n",
    "df['one_topic_name'] = df['one_topic'].map(topic_name_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Distribution (More than one topic per docs) \n",
    "- To reduce the numbers of outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np \n",
    "\n",
    "distance_matrix = cosine_similarity(np.array(topic_model.topic_embeddings_))\n",
    "dist_df = pd.DataFrame(distance_matrix, columns=topic_model.topic_labels_.values(), \n",
    "                       index=topic_model.topic_labels_.values())\n",
    "\n",
    "tmp = []\n",
    "for rec in dist_df.reset_index().to_dict('records'):\n",
    "    t1 = rec['index']\n",
    "    for t2 in rec:\n",
    "        if t2 == 'index': \n",
    "            continue\n",
    "        tmp.append(\n",
    "            {\n",
    "                'topic1': t1, \n",
    "                'topic2': t2, \n",
    "                'distance': rec[t2]\n",
    "            }\n",
    "        )\n",
    "\n",
    "pair_dist_df = pd.DataFrame(tmp)\n",
    "\n",
    "pair_dist_df = pair_dist_df[(pair_dist_df.topic1.map(\n",
    "      lambda x: not x.startswith('-1'))) & \n",
    "            (pair_dist_df.topic2.map(lambda x: not x.startswith('-1')))]\n",
    "pair_dist_df = pair_dist_df[pair_dist_df.topic1 < pair_dist_df.topic2]\n",
    "pair_dist_df.sort_values('distance', ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiples topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distr, topic_token_distr = topic_model.approximate_distribution(\n",
    "      docs, window = 5, calculate_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "tmp_dfs = []\n",
    "\n",
    "# iterating through different threshold levels\n",
    "for thr in tqdm.tqdm(np.arange(0, 0.35, 0.001)):\n",
    "    # calculating number of topics with probability > threshold for each document\n",
    "    tmp_df = pd.DataFrame(list(map(lambda x: len(list(filter(lambda y: y >= thr, x))), topic_distr))).rename(\n",
    "        columns = {0: 'num_topics'}\n",
    "    )\n",
    "    tmp_df['num_docs'] = 1\n",
    "    \n",
    "    tmp_df['num_topics_group'] = tmp_df['num_topics']\\\n",
    "        .map(lambda x: str(x) if x < 5 else '5+')\n",
    "    \n",
    "    # aggregating stats\n",
    "    tmp_df_aggr = tmp_df.groupby('num_topics_group', as_index = False).num_docs.sum()\n",
    "    tmp_df_aggr['threshold'] = thr\n",
    "    \n",
    "    tmp_dfs.append(tmp_df_aggr)\n",
    "\n",
    "num_topics_stats_df = pd.concat(tmp_dfs).pivot(index = 'threshold', \n",
    "                              values = 'num_docs',\n",
    "                              columns = 'num_topics_group').fillna(0)\n",
    "\n",
    "num_topics_stats_df = num_topics_stats_df.apply(lambda x: 100.*x/num_topics_stats_df.sum(axis = 1))\n",
    "\n",
    "# visualisation\n",
    "colormap = px.colors.sequential.YlGnBu\n",
    "px.area(num_topics_stats_df, \n",
    "       title = 'Distribution of number of topics',\n",
    "       labels = {'num_topics_group': 'number of topics',\n",
    "                'value': 'share of reviews, %'},\n",
    "       color_discrete_map = {\n",
    "          '0': colormap[0],\n",
    "          '1': colormap[3],\n",
    "          '2': colormap[4],\n",
    "          '3': colormap[5],\n",
    "          '4': colormap[6],\n",
    "          '5+': colormap[7]\n",
    "      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.13\n",
    "\n",
    "# define topic with probability > 0.13 for each document\n",
    "df['multiple_topics'] = list(map(\n",
    "    lambda doc_topic_distr: list(map(\n",
    "        lambda y: y[0], filter(lambda x: x[1] >= threshold, \n",
    "                               (enumerate(doc_topic_distr)))\n",
    "    )), topic_distr\n",
    "))\n",
    "\n",
    "# creating a dataset with docid, topic\n",
    "tmp_data = []\n",
    "\n",
    "for rec in df.to_dict('records'):\n",
    "    if len(rec['multiple_topics']) != 0:\n",
    "        mult_topics = rec['multiple_topics']\n",
    "    else:\n",
    "        mult_topics = [-1]\n",
    "        \n",
    "    for topic in mult_topics: \n",
    "        tmp_data.append(\n",
    "            {\n",
    "                'topic': topic,\n",
    "                'id': rec['Content'],\n",
    "            }\n",
    "        )\n",
    "            \n",
    "mult_topics_df = pd.DataFrame(tmp_data)\n",
    "df[\"multiple_topics_name\"] = df[\"multiple_topics\"].map(lambda x: [topic_name_to_id.get(i, \"No topic\") for i in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the porportion of topics per participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_topic.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Group and count\n",
    "counts_one_topic = df.groupby([\"Experiment\", \"one_topic_name\"]).size()\n",
    "\n",
    "# 2. Pivot\n",
    "counts_one_topic_pivot = counts_one_topic.unstack(fill_value=0)\n",
    "\n",
    "# 3. Convert to row-wise % (each row sums to 100%)\n",
    "perc_one_topic = counts_one_topic_pivot.div(counts_one_topic_pivot.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# 4. Optional stacked bar chart\n",
    "ax = perc_one_topic.plot.bar(stacked=True, figsize=(10,6))\n",
    "ax.set_ylabel(\"Percentage of Documents (%)\")\n",
    "ax.set_title(\"Percentage of one_topic_name by Experiment\")\n",
    "plt.legend(bbox_to_anchor=(1.0, 1.0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
